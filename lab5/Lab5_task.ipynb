{"cells":[{"cell_type":"markdown","metadata":{"id":"_DsfDI6DqBtO"},"source":["# Лабораторная работа № 5. Решение задачи классификации на примере прогноза состояния системы на основе данных о состоянии ее компонентов."]},{"cell_type":"markdown","metadata":{"id":"VmbTnG0-qBtc"},"source":["В работе проводится ознакомление с различными методами машинного обучения с учителем, решающих задачу классификации. СОздаются различные линейные и нелинейные модели и оценивается точность из прогноза."]},{"cell_type":"markdown","metadata":{"id":"aV2fRv3aqBtg"},"source":["## Введение"]},{"cell_type":"markdown","metadata":{"id":"EjyHwi_EqBti"},"source":["Современные радиолокационные станции (РЛС) – это структурно-сложные радиотехнические и информационные системы, характеризующиеся высокой надежностью функционирования и большим числом цифровых компонентов в своем составе. Одним из таких компонентов является блок усиления мощности (БУМ), задача которого усиливать передаваемый или принимаемый сигнал.\n","\n","Функционирование БУМ приводит к их нагреву, что может сказаться на снижении их работоспособности или даже привести к отказу. Под системой в этой работе мы будем понимать несколько БУМ, объединенных в единое целое. Тогда техническое состояние всей системы будет определяться техническим состоянием ее компонент, т.е. состоянием БУМ в данной работе. Техническое же состояние БУМ напрямую зависит от их температуры: при достижении определенного порога блок перестает работать и начинает охлаждаться. После охлаждения до определенной температуры он снова переходит в рабоспособное состояние.\n","\n","Основная задача - спрогнозировать увеличение температуры блоков усиления мощности на основании истории их функционирования и режима работы блоков, который задает интенсивность нагрева, и возможный выход из строя всей системы блоков. В лабораторной работе № 3 проводится статистический анализ данных тепловой нагрузки модельных БУМ, определяются пороговые значения температур, при которых происходит отключение блоков с целью их охлаждения. На основании пороговых температур вычислено состояние блоков в интервале \\[0, 1\\] и установлен простой критерий определения состояния системы - снижение среднего состояния всех блоков ниже определенного порогового значения. \n","\n","В данной лабораторной работе будут применены различные методы машинного обучения с учителем для установления зависимости состояния системы от состояний блоков и прогноза состояния системы."]},{"cell_type":"markdown","metadata":{"id":"_S9KJFqHqBtm"},"source":["## Описание исходных данных"]},{"cell_type":"markdown","metadata":{"id":"u4j3rBTXqBto"},"source":["Подключим стандартные пакеты для работы с данными и построения графиков"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gjwqQJm5qBtq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5Ed3QNatqBtw"},"source":["Загрузим файл с данными и выведем на экран первые 5 строк. Получим информацию по каждой колонке."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sxSFtxYEqBty"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state1</th>\n","      <th>state2</th>\n","      <th>state3</th>\n","      <th>state4</th>\n","      <th>state5</th>\n","      <th>state6</th>\n","      <th>state7</th>\n","      <th>state8</th>\n","      <th>state9</th>\n","      <th>system_state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.990954</td>\n","      <td>0.996330</td>\n","      <td>1.000000</td>\n","      <td>0.979060</td>\n","      <td>1.000000</td>\n","      <td>0.929844</td>\n","      <td>0.947907</td>\n","      <td>0.952991</td>\n","      <td>0.962632</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.838641</td>\n","      <td>0.806637</td>\n","      <td>0.820733</td>\n","      <td>0.813443</td>\n","      <td>0.797077</td>\n","      <td>0.736372</td>\n","      <td>0.720410</td>\n","      <td>0.780524</td>\n","      <td>0.794755</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.821185</td>\n","      <td>0.769370</td>\n","      <td>0.830724</td>\n","      <td>0.830488</td>\n","      <td>0.813958</td>\n","      <td>0.753848</td>\n","      <td>0.715018</td>\n","      <td>0.781899</td>\n","      <td>0.796795</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.687686</td>\n","      <td>0.604382</td>\n","      <td>0.676615</td>\n","      <td>0.708904</td>\n","      <td>0.624583</td>\n","      <td>0.638659</td>\n","      <td>0.576266</td>\n","      <td>0.615852</td>\n","      <td>0.651636</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.583539</td>\n","      <td>0.503571</td>\n","      <td>0.578079</td>\n","      <td>0.586587</td>\n","      <td>0.534546</td>\n","      <td>0.551319</td>\n","      <td>0.487111</td>\n","      <td>0.529548</td>\n","      <td>0.518788</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     state1    state2    state3    state4    state5    state6    state7  \\\n","0  0.990954  0.996330  1.000000  0.979060  1.000000  0.929844  0.947907   \n","1  0.838641  0.806637  0.820733  0.813443  0.797077  0.736372  0.720410   \n","2  0.821185  0.769370  0.830724  0.830488  0.813958  0.753848  0.715018   \n","3  0.687686  0.604382  0.676615  0.708904  0.624583  0.638659  0.576266   \n","4  0.583539  0.503571  0.578079  0.586587  0.534546  0.551319  0.487111   \n","\n","     state8    state9  system_state  \n","0  0.952991  0.962632           1.0  \n","1  0.780524  0.794755           1.0  \n","2  0.781899  0.796795           1.0  \n","3  0.615852  0.651636           1.0  \n","4  0.529548  0.518788           1.0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"Lab5_data.csv\")\n","df.head(5)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tKlxfuswqBt1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1205950 entries, 0 to 1205949\n","Data columns (total 10 columns):\n"," #   Column        Non-Null Count    Dtype  \n","---  ------        --------------    -----  \n"," 0   state1        1205950 non-null  float64\n"," 1   state2        1205950 non-null  float64\n"," 2   state3        1205950 non-null  float64\n"," 3   state4        1205950 non-null  float64\n"," 4   state5        1205950 non-null  float64\n"," 5   state6        1205950 non-null  float64\n"," 6   state7        1205950 non-null  float64\n"," 7   state8        1205950 non-null  float64\n"," 8   state9        1205950 non-null  float64\n"," 9   system_state  1205950 non-null  float64\n","dtypes: float64(10)\n","memory usage: 92.0 MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"VgrvAO1VqBt2"},"source":["Колонки **state1 - state9** содержат состояние блока 1 - 9 в виде вещественного числа в интервале \\[0, 1\\]. При этом значению 1 соответствует работоспособное состояние с минимальной температурой, в состоянию 0 - выключенное состояние, когда блок находится в режиме обхлаждения. Колонка **system_state** обозначает состояние системы: 1 - работоспособна, 0 - нерабоспособна. Все колонки имеют тип **float64**."]},{"cell_type":"markdown","metadata":{"id":"mt-LyBPmqBt4"},"source":["## Подготовка данных"]},{"cell_type":"markdown","metadata":{"id":"uIKiNU2qqBt5"},"source":["Для использования моделей машинного обучения с учителем необходимо специальным образом подготовить данные: сформировать обучающую выборку, на которой модель будет \"учиться\", т.е. подстраивать свои внутренние параметры, тестовую выборку, на которой будет определяться точность модели в процессе ее обучения, а также валидационную выборку, на которой проверяется итогое качество работы модели. \n","\n","Вместо выделения валидационной выборки можно использовать механизм кросс-валидации.В основе метода лежит разделение исходного множества данных на **k** примерно равных блоков, например 5. Затем на **k-1**, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется **k** раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.\n","![Cross-validation](https://wiki.loginom.ru/images/cross-validation.svg)"]},{"cell_type":"markdown","metadata":{"id":"L-clFbuQqBt7"},"source":["Кросс-валидация имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели:\n","\n","- Распределение классов оказывается более равномерным, что улучшает качество обучения.\n","- Если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная оценка будет более достоверной.\n","\n","В дальнейшем в этой лабораторной работе будем использовать разбиение на 5 блоков с помощью метода **[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=k%20fold#sklearn.model_selection.KFold 'KFold')**."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"kbvqQcwKqBt9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","Train index:  [      0       1       2 ... 1205945 1205946 1205947]\n","Test index:  [      4       5      22 ... 1205940 1205948 1205949]\n","Fold 2\n","Train index:  [      0       2       4 ... 1205947 1205948 1205949]\n","Test index:  [      1       3      10 ... 1205936 1205941 1205946]\n","Fold 3\n","Train index:  [      0       1       2 ... 1205947 1205948 1205949]\n","Test index:  [      6       7       9 ... 1205926 1205927 1205944]\n","Fold 4\n","Train index:  [      1       3       4 ... 1205947 1205948 1205949]\n","Test index:  [      0       2      16 ... 1205934 1205937 1205942]\n","Fold 5\n","Train index:  [      0       1       2 ... 1205946 1205948 1205949]\n","Test index:  [      8      13      25 ... 1205943 1205945 1205947]\n"]}],"source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","X = df.loc[:, 'state1':'state9']\n","y = df['system_state'].astype(int)\n","\n","for i, (train_index, test_index) in enumerate(kf.split(X), start=1):\n","    print('Fold {}'.format(i))\n","    print('Train index: ', train_index)\n","    print('Test index: ', test_index)"]},{"cell_type":"markdown","metadata":{"id":"EJuzMzGlqBt_"},"source":["## Линейные модели машинного обучения"]},{"cell_type":"markdown","metadata":{"id":"_LeJCG4YqBt_"},"source":["Задача определения состояния системы по известным состояниям блоков является задачей бинарной классификации. Среди линейных моделей будем использовать линейную регрессию, линейную регрессию с L1 и L2-регуляризацией, а также логистическую регрессию. Подробное описание работы этих моделей можно прочитать на сайте [Scikit Learn](https://scikit-learn.org/stable/modules/linear_model.html 'Scikit Learn')."]},{"cell_type":"markdown","metadata":{"id":"4q9msIwFqEL8"},"source":["#### **Задание 1** "]},{"cell_type":"markdown","metadata":{"id":"gR_4Iew-qBuB"},"source":["Сделаем процесс обучения различных моделей универсальным. Для этого напишем функцию **regr_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели регрессии, функцию **class_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели классификации, и функцию **train(model, model_name, evaluate, kfold, X, y)**, которая обучает заданную модель **model** с использованием механизма кросс-валидации **kfold**.\n","\n","Точность - относительная доля правильно спрогнозированных значений."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5XlMFRASqBuC"},"outputs":[],"source":["def regr_accuracy(y_pred, y_test):\n","    # R2\n","\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","\n","    TP_TN = y_pred == y_test\n","\n","    return TP_TN.sum() / len(y_pred)\n","\n","    # from sklearn.metrics import mean_squared_error\n","\n","    # mse = mean_squared_error(y_test, y_pred)\n","    # return mse\n","\n","    # from sklearn.metrics import r2_score\n","\n","    # return r2_score(y_test, y_pred)\n","\n","def class_accuracy(y_pred, y_test):\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","    \n","    # напишите здесь ваш код\n","    \n","    return 0\n","\n","def train(model, model_name, evaluate, kfold, X, y):\n","    # model - модель для прогноза, обладающая методами fit(), predict()\n","    # model_name - название модели, строковый тип\n","    # evaluate - функция для расчета точности, например функция regr_accuracy() или class_accuracy()\n","    # kfold - объект KFold\n","    # X - признаки\n","    # y - целевая переменная\n","    print('Train model: '+model_name)\n","    scores = []\n","    for train_index, test_index in kfold.split(X):\n","        X_train, X_test = X.loc[train_index].to_numpy(), X.loc[test_index].to_numpy()\n","        y_train, y_test = y.loc[train_index].to_numpy(), y.loc[test_index].to_numpy()\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test).astype(int)\n","        score = evaluate(y_pred, y_test)\n","        scores.append(score)\n","\n","    mean_score = np.mean(scores)\n","    print('Mean score = {:.5f}'.format(mean_score))\n","    return mean_score"]},{"cell_type":"markdown","metadata":{"id":"B5yEVTk8qBuE"},"source":["### Линейная регрессия"]},{"cell_type":"markdown","metadata":{"id":"o1LF2lQXqBuF"},"source":["В линейных моделях целевая переменная $\\hat{y}$ определяется как линейная комбинация известных переменных (признаков):\n","\n","$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n","\n","В модели линейной регрессии коэффициенты $w = (w_1, ..., w_p)$ подбираются таким образом, чтобы минимизировать сумму квадратов отклонений рассчитанных значений целевой переменной от истинных значений:\n","\n","$$\\min_{w} || X w - y||_2^2$$\n","\n","Важно отметить, что линейные модели чувствительны к абсолютным значениям признаков, поэтому следует перед применением линейных моделей провести нормирование исходных данных (обычно на интервал \\[0,1\\]). Также применение линейных моделей основано на предположении о линейной независимости признаков, поэтому следует стараться не использовать в качестве признаков коррелированные признаки. В противном случае модель будет чувствительна к шумам, т.е. случайным выбросам в значениях признаков."]},{"cell_type":"markdown","metadata":{"id":"ZrfRKpNhqBuG"},"source":["Создадим и обучим модель **[LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression 'LinearRegression')**. Запишем точность модели в словарь **scores**."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"t1yueQNJqBuH"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: linear regression\n","Mean score = 0.68160\n"]}],"source":["from sklearn import linear_model\n","\n","lin_reg = linear_model.LinearRegression()\n","\n","scores = dict()\n","\n","score = train(lin_reg, 'linear regression', regr_accuracy, kf, X, y)\n","scores['linear regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"8SOVicj5qBuI"},"source":["### Линейная регрессия c L1 и L2 регуляризацией"]},{"cell_type":"markdown","metadata":{"id":"DGNWt1qDqBuJ"},"source":["Если размер обучающей выборки невелик, а число признаков, наоборот, достаточно велико, то коэффициенты модели могут быть подобраны таким образом, чтобы модель максимально точно учитывала все точки из обучающей выборки, при этом вне обучающей выборки модель будет давать большую ошибку. Это явление носит название переобучения. Одним из способов препятствовать переобучению является механизмы регуляризации. Он ограничивает значения коэффицентов $w = (w_1, ..., w_p)$, используемых в модели.\n","\n","L1-регуляризация вносит дополнительный \"штраф\", пропорциональный модулю значения коэффициента:\n","$$\\min_{w} ||X w - y||_2 ^ 2 + \\alpha ||w||_1$$\n","\n","L2-регуляризация вносит дополнительный \"штраф\", пропорциональный квадрату модуля значения коэффициента:\n","$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2$$\n","\n","Параметр $\\alpha$ задает \"силу\" регуляризации. L1-регуляризация приведет к тому, что все несущественные признаки будут иметь вес, равный 0. L2-регуляризация приведет к тому, что несущественные признаки будут иметь околонулевые веса. Продемонстрируем это на примере. Создадим и обучим модели **[Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso 'Lasso')** (L1-регуляризация) и **[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge 'Ridge')** (L2-регуляризация).\n","\n","Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Lasso**."]},{"cell_type":"markdown","metadata":{"id":"WA9AmWF9qRZ4"},"source":["#### **Задание 2** "]},{"cell_type":"code","execution_count":18,"metadata":{"id":"BbZqmJWUqBuJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha = 0.0001\n","Coefficients:  [0.16542942 0.16946404 0.16572914 0.16082697 0.16851875 0.16864115\n"," 0.16507533 0.16953335 0.17136388]\n","Alpha = 0.001\n","Coefficients:  [0.16326228 0.16731439 0.16351531 0.15859281 0.16649824 0.16657605\n"," 0.16306425 0.16737437 0.16928289]\n","Alpha = 0.01\n","Coefficients:  [0.14159091 0.14581789 0.14137704 0.13625125 0.1462931  0.145925\n"," 0.14295352 0.14578453 0.14847301]\n","Alpha = 0.1\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Alpha = 1\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","    \n","    lasso = linear_model.Lasso(alpha = alpha)\n","    lasso.fit(X,y)\n","    \n","    print('Coefficients: ', lasso.coef_)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# from sklearn.linear_model import Lasso\n","# from sklearn.model_selection import GridSearchCV\n","\n","# # Создаем модель Lasso\n","# lasso = Lasso()\n","\n","# # Создаем словарь параметров для GridSearchCV\n","# parameters = {'alpha': [1e-4, 1e-3, 0.01, 0.1, 1]}\n","\n","# # Создаем объект GridSearchCV\n","# lasso_cv = GridSearchCV(lasso, parameters, cv=5)\n","\n","# # Подготавливаем данные\n","# X = X\n","# y = y\n","\n","# # Выполняем подбор параметров\n","# lasso_cv.fit(X, y)\n","\n","# # Выводим оптимальные параметры\n","# print(\"Лучшие параметры: \", lasso_cv.best_params_)\n","# print(\"Лучшая оценка: \", lasso_cv.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"bEtMb7HnqBuK"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ijIaEpdmqBuK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: lasso\n","Mean score = 0.68141\n"]}],"source":["lasso = linear_model.Lasso(alpha = 0.0001)\n","score = train(lasso, 'lasso', regr_accuracy, kf, X, y)\n","scores['lasso'] = score"]},{"cell_type":"markdown","metadata":{"id":"lT6aVlFvqUWP"},"source":["#### **Задание 3** "]},{"cell_type":"markdown","metadata":{"id":"jC4eciIHqBuL"},"source":["Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Ridge**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbCQ_NzuqBuM"},"outputs":[{"ename":"ValueError","evalue":"\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1131, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 883, in fit\n    self.coef_, self.n_iter_ = _ridge_regression(\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 646, in _ridge_regression\n    raise ValueError(\nValueError: Number of targets and number of penalties do not correspond: 50 != 1\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32me:\\work\\vuz\\IUS\\IUS\\lab5\\Lab5_task.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_task.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m y\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_task.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Выполняем подбор параметров\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_task.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ridge_cv\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_task.ipynb#X44sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Выводим оптимальные параметры\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_task.ipynb#X44sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mЛучшие параметры: \u001b[39m\u001b[39m\"\u001b[39m, ridge_cv\u001b[39m.\u001b[39mbest_params_)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1131, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 883, in fit\n    self.coef_, self.n_iter_ = _ridge_regression(\n  File \"C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 646, in _ridge_regression\n    raise ValueError(\nValueError: Number of targets and number of penalties do not correspond: 50 != 1\n"]}],"source":["# напишите здесь ваш код\n","from sklearn.linear_model import Ridge\n","\n","# Создаем модель Lasso\n","ridge = Ridge()\n","\n","# Создаем словарь параметров для GridSearchCV\n","parameters = {'alpha': [np.linspace(1e-4, 1e10)]}\n","\n","# Создаем объект GridSearchCV\n","ridge_cv = GridSearchCV(ridge, parameters, cv=5)\n","\n","# Подготавливаем данные\n","X = X\n","y = y\n","\n","# Выполняем подбор параметров\n","ridge_cv.fit(X, y)\n","\n","# Выводим оптимальные параметры\n","print(\"Лучшие параметры: \", ridge_cv.best_params_)\n","print(\"Лучшая оценка: \", ridge_cv.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"Mx1E56OwqBuM"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvicDflUqBuM"},"outputs":[],"source":["ridge = linear_model.Ridge(alpha = )\n","score = train(ridge, 'ridge', regr_accuracy, kf, X, y)\n","scores['ridge'] = score"]},{"cell_type":"markdown","metadata":{"id":"V18B9WFqqBuN"},"source":["Как видим, **Lasso** просто занулила все коэффициенты при $\\alpha>0.01$."]},{"cell_type":"markdown","metadata":{"id":"_bm3DSxiqBuN"},"source":["### Логистическая регрессия"]},{"cell_type":"markdown","metadata":{"id":"Zk3mvsA_qBuO"},"source":["Если на выходе линейной регрессии получается просто вещественное число, то в логистической регрессии это число преобразуется с помощью логистической функции в отрезок \\[0,1\\], а потому может трактоваться как вероятность получения на выходе дискретного значения 1. \n","\n","$$f(y)=\\dfrac{1}{1+e^{-y}}$$\n","\n","Таким образом, модель логистической регрессии может успешно использоваться как бинарный классификатор. Логистическая регрессия минимизирует следующую величину (L1 и L2 регуляризация уже включены и контролируются параметрами $C$ - \"сила\" регуляризации (малые значения - \"сильная\" регуляризация), $\\rho$ - относительный вклад L1-регуляризации):\n","\n","$$\\min_{w, c} \\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1)$$\n","\n","Создадим модель **[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression 'Logistic Regression')** и обучим ее.\n","\n","Подберите оптимальное значение параметра регуляризации **С** и тип регуляризации **penalty**. "]},{"cell_type":"markdown","metadata":{"id":"N5CGOf2GqeeK"},"source":["#### **Задание 4** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1P4VdrGSqBuP"},"outputs":[],"source":["# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"IW1aI40TqBuP"},"source":["Обучим модель с оптимальным значением параметра **С**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cctaYPAcqBuP"},"outputs":[],"source":["logistic_regr = linear_model.LogisticRegression(penalty = , C=, solver='lbfgs')\n","score = train(logistic_regr, 'logistic regression', class_accuracy, kf, X, y)\n","scores['logistic regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"wYfkTsd0qBuQ"},"source":["## Метод опорных векторов"]},{"cell_type":"markdown","metadata":{"id":"NdFpL7e3qBuQ"},"source":["Этот метод применим для решения как задач классификации, так и регрессии, и кластеризации. Основными достоинствами метода являются:\n","\n","- эффективность при большой размерности пространства признаков\n","- в процессе обучения запоминается только подвыборка обучающей выборки - опорные вектора, т.е. требует меньший объем памяти\n","- можно применять разные ядра (kernels) для формирования модели\n","\n","Недостатком метода опорных векторов является то, что в случае, когда размерность пространства признаков много больше объема обучающей выборки, на результат работы модели сильно влияет выбор ядра. Также этот метод не позволяет быстро и просто получить вероятность прогноза.\n","\n","С математической точки зрения, метод опорных векторов проводит гипер-плоскость, которая разделяет один класс от другого. При этом граница проводится так, что быть расположенной максимально далеко от каждой из точек.\n","![SVC](https://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png)\n","\n","Функция ядра определяет, какие признаки будут использоваться в качестве переменных в гиперпространстве, в котором проводится гипер-плоскость. Например, для линейного ядра $\\langle x, x'\\rangle$ берутся исходные признаки, для полиномиального ядра - полиномы от исходных признаков $(\\gamma \\langle x, x'\\rangle + r)^d$, для radial-basis-function (rbf) - экспоненциальная функция $\\exp(-\\gamma \\|x-x'\\|^2)$.\n","\n","Построим модель Support Vector Classifier - [**SVC**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC 'SVC') для различных ядер. Заранее уменьшим размер выборки, что позволит проводить обучения в разумное время (метод опорных векторов довольно долго обучается).\n","\n","Определите оптимальное значение параметра регуляризации **С** и типа ядра **kernel**."]},{"cell_type":"markdown","metadata":{"id":"ivF5OJxVqhSq"},"source":["#### **Задание 5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0bgmnaoqBuR"},"outputs":[],"source":["from sklearn.svm import SVC\n","X_svc = X.iloc[:10000, :]\n","y_svc = y[:10000]\n","\n","# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"sfsLap6cqBuR"},"source":["Обучим модель с оптимальным значением параметра **С** и типом ядра **kernel**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scitVGNbqBuS"},"outputs":[],"source":["svc = SVC(C=, kernel=, gamma='auto')\n","score = train(svc, 'svc', class_accuracy, kf, X_svc, y_svc)\n","scores['svc'] = score"]},{"cell_type":"markdown","metadata":{"id":"VNehNP8gqBuS"},"source":["## Дерево решений"]},{"cell_type":"markdown","metadata":{"id":"UP-bW4hwqBuS"},"source":["В модели дерева решений (Decision Tree) в процессе обучения строится алгоритм, по которому выполняется прогноз модели. При этом алгоритм представляет из себя дерево, каждый лист которого - это проверка на то, что какой-либо признак из обучающей выборки принимает определенное значение. Пример дерева решений приведен на рисунке ниже.\n","![Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png)\n","\n","Преимуществами такого метода являются:\n","- простота визуализации и хорошая интерпретируемость алгоритма прогноза\n","- не требуется нормализация данных\n","- скорость прогноза пропорциональна логарифму объема выборки, т.е. этот метод быстрый\n","- может обрабатывать как числовые, так и категориальные данные\n","\n","Недостатками метода являются:\n","- деревья легко переобучаются\n","- небольшие изменения в обучающей выборке могут привести к перестойке всего дерева, т.е. метод нестабилен\n","- предсказания деревьев являются кусочно-постоянными, поэтому не годятся для экстраполирования\n","- требуется сбалансировать обучающую выборку по классам, чтобы не допустить \"перекоса\" дерева в сторону какого-либо класса\n","\n","Конкретную математическую реализалицаю алгоритма построения дерева решений можно изучить, например, [здесь.](https://scikit-learn.org/stable/modules/tree.html)\n","\n","Создадим модель [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier 'DecisionTreeClassifier') и обучим ее. Для того, чтобы предотвратить переобучение дерева, обычно ограничивается максимальная глубина дерева - параметр **max_depth**, а также минимальное число элементов из обучающей выборки, приходящееся на определнный лист, чтобы можно было с него сделать новое ветвление - параметр **min_samples_split**.\n","\n","Подберите оптимальное значение параметров **max_depth** и **min_samples_split**."]},{"cell_type":"markdown","metadata":{"id":"3dc10J6-qq_P"},"source":["#### **Задание 6** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSShPADxqBuT"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# напишите здесь ваш код"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQExOWvOqBuT"},"outputs":[],"source":["# напишите здесь ваш код"]},{"cell_type":"markdown","metadata":{"id":"NJB7z7RiqBuU"},"source":["Создадим модель с оптимальными значениями параметров **max_depth** и **min_samples_split**. Добавим ее в словарь **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STjh7rAuqBuU"},"outputs":[],"source":["dtc = DecisionTreeClassifier(max_depth=, min_samples_split=, min_samples_leaf=1, random_state=0)\n","score = train(dtc, 'decision tree', class_accuracy, kf, X, y)\n","scores['decision tree'] = score"]},{"cell_type":"markdown","metadata":{"id":"L54zzd7KqBuU"},"source":["## Сравнение различных моделей"]},{"cell_type":"markdown","metadata":{"id":"xEaMPqy-qBuU"},"source":["Отобразим на графике точность работы каждой построенной модели. Для этого будем использовать значения из словаря **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6SRzljXqBuV"},"outputs":[],"source":["plt.figure(figsize=(10,5))\n","xx = list(scores.keys())\n","yy = list(scores.values())\n","rects = plt.bar(xx, yy)\n","plt.ylim(0.7, 0.9)\n","plt.ylabel('Accuracy')\n","for i, rect in enumerate(rects):\n","    yloc = rect.get_height()\n","    xloc = rect.get_x() + rect.get_width() / 4\n","    plt.annotate(round(yy[i], 4), xy=(xloc, yloc), xytext=(xloc, 10),\n","                            textcoords=\"offset points\",\n","                            va='center',\n","                            color='black', clip_on=True)"]},{"cell_type":"markdown","metadata":{"id":"mFqOwK_mqBuV"},"source":["# Выводы"]},{"cell_type":"markdown","metadata":{"id":"u_haAZPuqwqf"},"source":["#### **Задание 7** "]},{"cell_type":"markdown","metadata":{"id":"XXjkE-WUqBuV"},"source":["Напишите выводы по лабораторной работе"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfKKrNttqBuW"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
