{"cells":[{"cell_type":"markdown","metadata":{"id":"_DsfDI6DqBtO"},"source":["# Лабораторная работа № 5. Решение задачи классификации на примере прогноза состояния системы на основе данных о состоянии ее компонентов."]},{"cell_type":"markdown","metadata":{"id":"VmbTnG0-qBtc"},"source":["В работе проводится ознакомление с различными методами машинного обучения с учителем, решающих задачу классификации. СОздаются различные линейные и нелинейные модели и оценивается точность из прогноза."]},{"cell_type":"markdown","metadata":{"id":"aV2fRv3aqBtg"},"source":["## Введение"]},{"cell_type":"markdown","metadata":{"id":"EjyHwi_EqBti"},"source":["Современные радиолокационные станции (РЛС) – это структурно-сложные радиотехнические и информационные системы, характеризующиеся высокой надежностью функционирования и большим числом цифровых компонентов в своем составе. Одним из таких компонентов является блок усиления мощности (БУМ), задача которого усиливать передаваемый или принимаемый сигнал.\n","\n","Функционирование БУМ приводит к их нагреву, что может сказаться на снижении их работоспособности или даже привести к отказу. Под системой в этой работе мы будем понимать несколько БУМ, объединенных в единое целое. Тогда техническое состояние всей системы будет определяться техническим состоянием ее компонент, т.е. состоянием БУМ в данной работе. Техническое же состояние БУМ напрямую зависит от их температуры: при достижении определенного порога блок перестает работать и начинает охлаждаться. После охлаждения до определенной температуры он снова переходит в рабоспособное состояние.\n","\n","Основная задача - спрогнозировать увеличение температуры блоков усиления мощности на основании истории их функционирования и режима работы блоков, который задает интенсивность нагрева, и возможный выход из строя всей системы блоков. В лабораторной работе № 3 проводится статистический анализ данных тепловой нагрузки модельных БУМ, определяются пороговые значения температур, при которых происходит отключение блоков с целью их охлаждения. На основании пороговых температур вычислено состояние блоков в интервале \\[0, 1\\] и установлен простой критерий определения состояния системы - снижение среднего состояния всех блоков ниже определенного порогового значения. \n","\n","В данной лабораторной работе будут применены различные методы машинного обучения с учителем для установления зависимости состояния системы от состояний блоков и прогноза состояния системы."]},{"cell_type":"markdown","metadata":{"id":"_S9KJFqHqBtm"},"source":["## Описание исходных данных"]},{"cell_type":"markdown","metadata":{"id":"u4j3rBTXqBto"},"source":["Подключим стандартные пакеты для работы с данными и построения графиков"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"gjwqQJm5qBtq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5Ed3QNatqBtw"},"source":["Загрузим файл с данными и выведем на экран первые 5 строк. Получим информацию по каждой колонке."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"sxSFtxYEqBty"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>state1</th>\n","      <th>state2</th>\n","      <th>state3</th>\n","      <th>state4</th>\n","      <th>state5</th>\n","      <th>state6</th>\n","      <th>state7</th>\n","      <th>state8</th>\n","      <th>state9</th>\n","      <th>system_state</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.990954</td>\n","      <td>0.996330</td>\n","      <td>1.000000</td>\n","      <td>0.979060</td>\n","      <td>1.000000</td>\n","      <td>0.929844</td>\n","      <td>0.947907</td>\n","      <td>0.952991</td>\n","      <td>0.962632</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.838641</td>\n","      <td>0.806637</td>\n","      <td>0.820733</td>\n","      <td>0.813443</td>\n","      <td>0.797077</td>\n","      <td>0.736372</td>\n","      <td>0.720410</td>\n","      <td>0.780524</td>\n","      <td>0.794755</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.821185</td>\n","      <td>0.769370</td>\n","      <td>0.830724</td>\n","      <td>0.830488</td>\n","      <td>0.813958</td>\n","      <td>0.753848</td>\n","      <td>0.715018</td>\n","      <td>0.781899</td>\n","      <td>0.796795</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.687686</td>\n","      <td>0.604382</td>\n","      <td>0.676615</td>\n","      <td>0.708904</td>\n","      <td>0.624583</td>\n","      <td>0.638659</td>\n","      <td>0.576266</td>\n","      <td>0.615852</td>\n","      <td>0.651636</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.583539</td>\n","      <td>0.503571</td>\n","      <td>0.578079</td>\n","      <td>0.586587</td>\n","      <td>0.534546</td>\n","      <td>0.551319</td>\n","      <td>0.487111</td>\n","      <td>0.529548</td>\n","      <td>0.518788</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     state1    state2    state3    state4    state5    state6    state7  \\\n","0  0.990954  0.996330  1.000000  0.979060  1.000000  0.929844  0.947907   \n","1  0.838641  0.806637  0.820733  0.813443  0.797077  0.736372  0.720410   \n","2  0.821185  0.769370  0.830724  0.830488  0.813958  0.753848  0.715018   \n","3  0.687686  0.604382  0.676615  0.708904  0.624583  0.638659  0.576266   \n","4  0.583539  0.503571  0.578079  0.586587  0.534546  0.551319  0.487111   \n","\n","     state8    state9  system_state  \n","0  0.952991  0.962632           1.0  \n","1  0.780524  0.794755           1.0  \n","2  0.781899  0.796795           1.0  \n","3  0.615852  0.651636           1.0  \n","4  0.529548  0.518788           1.0  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"Lab5_data.csv\")\n","df.head(5)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"tKlxfuswqBt1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1205950 entries, 0 to 1205949\n","Data columns (total 10 columns):\n"," #   Column        Non-Null Count    Dtype  \n","---  ------        --------------    -----  \n"," 0   state1        1205950 non-null  float64\n"," 1   state2        1205950 non-null  float64\n"," 2   state3        1205950 non-null  float64\n"," 3   state4        1205950 non-null  float64\n"," 4   state5        1205950 non-null  float64\n"," 5   state6        1205950 non-null  float64\n"," 6   state7        1205950 non-null  float64\n"," 7   state8        1205950 non-null  float64\n"," 8   state9        1205950 non-null  float64\n"," 9   system_state  1205950 non-null  float64\n","dtypes: float64(10)\n","memory usage: 92.0 MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"VgrvAO1VqBt2"},"source":["Колонки **state1 - state9** содержат состояние блока 1 - 9 в виде вещественного числа в интервале \\[0, 1\\]. При этом значению 1 соответствует работоспособное состояние с минимальной температурой, в состоянию 0 - выключенное состояние, когда блок находится в режиме обхлаждения. Колонка **system_state** обозначает состояние системы: 1 - работоспособна, 0 - нерабоспособна. Все колонки имеют тип **float64**."]},{"cell_type":"markdown","metadata":{"id":"mt-LyBPmqBt4"},"source":["## Подготовка данных"]},{"cell_type":"markdown","metadata":{"id":"uIKiNU2qqBt5"},"source":["Для использования моделей машинного обучения с учителем необходимо специальным образом подготовить данные: сформировать обучающую выборку, на которой модель будет \"учиться\", т.е. подстраивать свои внутренние параметры, тестовую выборку, на которой будет определяться точность модели в процессе ее обучения, а также валидационную выборку, на которой проверяется итогое качество работы модели. \n","\n","Вместо выделения валидационной выборки можно использовать механизм кросс-валидации.В основе метода лежит разделение исходного множества данных на **k** примерно равных блоков, например 5. Затем на **k-1**, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется **k** раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.\n","![Cross-validation](https://wiki.loginom.ru/images/cross-validation.svg)"]},{"cell_type":"markdown","metadata":{"id":"L-clFbuQqBt7"},"source":["Кросс-валидация имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели:\n","\n","- Распределение классов оказывается более равномерным, что улучшает качество обучения.\n","- Если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная оценка будет более достоверной.\n","\n","В дальнейшем в этой лабораторной работе будем использовать разбиение на 5 блоков с помощью метода **[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=k%20fold#sklearn.model_selection.KFold 'KFold')**."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"kbvqQcwKqBt9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","Train index:  [      0       1       2 ... 1205946 1205948 1205949]\n","Test index:  [      5       8      16 ... 1205929 1205934 1205947]\n","Fold 2\n","Train index:  [      0       2       3 ... 1205946 1205947 1205949]\n","Test index:  [      1       4       9 ... 1205940 1205942 1205948]\n","Fold 3\n","Train index:  [      1       4       5 ... 1205947 1205948 1205949]\n","Test index:  [      0       2       3 ... 1205944 1205945 1205946]\n","Fold 4\n","Train index:  [      0       1       2 ... 1205946 1205947 1205948]\n","Test index:  [      7      13      17 ... 1205938 1205943 1205949]\n","Fold 5\n","Train index:  [      0       1       2 ... 1205947 1205948 1205949]\n","Test index:  [     14      19      22 ... 1205935 1205937 1205939]\n"]}],"source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","X = df.loc[:, 'state1':'state9']\n","y = df['system_state'].astype(int)\n","\n","for i, (train_index, test_index) in enumerate(kf.split(X), start=1):\n","    print('Fold {}'.format(i))\n","    print('Train index: ', train_index)\n","    print('Test index: ', test_index)"]},{"cell_type":"markdown","metadata":{"id":"EJuzMzGlqBt_"},"source":["## Линейные модели машинного обучения"]},{"cell_type":"markdown","metadata":{"id":"_LeJCG4YqBt_"},"source":["Задача определения состояния системы по известным состояниям блоков является задачей бинарной классификации. Среди линейных моделей будем использовать линейную регрессию, линейную регрессию с L1 и L2-регуляризацией, а также логистическую регрессию. Подробное описание работы этих моделей можно прочитать на сайте [Scikit Learn](https://scikit-learn.org/stable/modules/linear_model.html 'Scikit Learn')."]},{"cell_type":"markdown","metadata":{"id":"4q9msIwFqEL8"},"source":["#### **Задание 1** "]},{"cell_type":"markdown","metadata":{"id":"gR_4Iew-qBuB"},"source":["Сделаем процесс обучения различных моделей универсальным. Для этого напишем функцию **regr_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели регрессии, функцию **class_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели классификации, и функцию **train(model, model_name, evaluate, kfold, X, y)**, которая обучает заданную модель **model** с использованием механизма кросс-валидации **kfold**.\n","\n","Точность - относительная доля правильно спрогнозированных значений."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"5XlMFRASqBuC"},"outputs":[],"source":["def regr_accuracy(y_pred, y_test):\n","\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","\n","    TP_TN = y_pred.astype(int) == y_test\n","\n","    return TP_TN.sum() / len(y_pred)\n","\n","    # R2\n","    # from sklearn.metrics import r2_score\n","\n","    # return r2_score(y_test, y_pred)\n","\n","def class_accuracy(y_pred, y_test):\n","    # y_pred - прогнозные значения\n","    # y_test - истинные значения\n","    \n","    # напишите здесь ваш код\n","    \n","    return regr_accuracy(y_pred=y_pred, y_test=y_test)\n","\n","def train(model, model_name, evaluate, kfold, X, y):\n","    # model - модель для прогноза, обладающая методами fit(), predict()\n","    # model_name - название модели, строковый тип\n","    # evaluate - функция для расчета точности, например функция regr_accuracy() или class_accuracy()\n","    # kfold - объект KFold\n","    # X - признаки\n","    # y - целевая переменная\n","    print('Train model: '+model_name)\n","    scores = []\n","    for train_index, test_index in kfold.split(X):\n","        X_train, X_test = X.loc[train_index], X.loc[test_index]\n","        y_train, y_test = y.loc[train_index], y.loc[test_index]\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        score = evaluate(y_pred, y_test)\n","        scores.append(score)\n","\n","    mean_score = np.mean(scores)\n","    print('Mean score = {:.5f}'.format(mean_score))\n","    return mean_score"]},{"cell_type":"markdown","metadata":{"id":"B5yEVTk8qBuE"},"source":["### Линейная регрессия"]},{"cell_type":"markdown","metadata":{"id":"o1LF2lQXqBuF"},"source":["В линейных моделях целевая переменная $\\hat{y}$ определяется как линейная комбинация известных переменных (признаков):\n","\n","$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n","\n","В модели линейной регрессии коэффициенты $w = (w_1, ..., w_p)$ подбираются таким образом, чтобы минимизировать сумму квадратов отклонений рассчитанных значений целевой переменной от истинных значений:\n","\n","$$\\min_{w} || X w - y||_2^2$$\n","\n","Важно отметить, что линейные модели чувствительны к абсолютным значениям признаков, поэтому следует перед применением линейных моделей провести нормирование исходных данных (обычно на интервал \\[0,1\\]). Также применение линейных моделей основано на предположении о линейной независимости признаков, поэтому следует стараться не использовать в качестве признаков коррелированные признаки. В противном случае модель будет чувствительна к шумам, т.е. случайным выбросам в значениях признаков."]},{"cell_type":"markdown","metadata":{"id":"ZrfRKpNhqBuG"},"source":["Создадим и обучим модель **[LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression 'LinearRegression')**. Запишем точность модели в словарь **scores**."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"t1yueQNJqBuH"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: linear regression\n"]},{"name":"stdout","output_type":"stream","text":["Mean score = 0.68161\n"]}],"source":["from sklearn import linear_model\n","\n","lin_reg = linear_model.LinearRegression()\n","\n","scores = dict()\n","\n","score = train(lin_reg, 'linear regression', regr_accuracy, kf, X, y)\n","scores['linear regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"8SOVicj5qBuI"},"source":["### Линейная регрессия c L1 и L2 регуляризацией"]},{"cell_type":"markdown","metadata":{"id":"DGNWt1qDqBuJ"},"source":["Если размер обучающей выборки невелик, а число признаков, наоборот, достаточно велико, то коэффициенты модели могут быть подобраны таким образом, чтобы модель максимально точно учитывала все точки из обучающей выборки, при этом вне обучающей выборки модель будет давать большую ошибку. Это явление носит название переобучения. Одним из способов препятствовать переобучению является механизмы регуляризации. Он ограничивает значения коэффицентов $w = (w_1, ..., w_p)$, используемых в модели.\n","\n","L1-регуляризация вносит дополнительный \"штраф\", пропорциональный модулю значения коэффициента:\n","$$\\min_{w} ||X w - y||_2 ^ 2 + \\alpha ||w||_1$$\n","\n","L2-регуляризация вносит дополнительный \"штраф\", пропорциональный квадрату модуля значения коэффициента:\n","$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2$$\n","\n","Параметр $\\alpha$ задает \"силу\" регуляризации. L1-регуляризация приведет к тому, что все несущественные признаки будут иметь вес, равный 0. L2-регуляризация приведет к тому, что несущественные признаки будут иметь околонулевые веса. Продемонстрируем это на примере. Создадим и обучим модели **[Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso 'Lasso')** (L1-регуляризация) и **[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge 'Ridge')** (L2-регуляризация).\n","\n","Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Lasso**."]},{"cell_type":"markdown","metadata":{"id":"WA9AmWF9qRZ4"},"source":["#### **Задание 2** "]},{"cell_type":"code","execution_count":28,"metadata":{"id":"BbZqmJWUqBuJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha = 0.0001\n","Score:  0.6814113354616692\n","Coefficients:  [0.16542942 0.16946404 0.16572914 0.16082697 0.16851875 0.16864115\n"," 0.16507533 0.16953335 0.17136388]\n","Alpha = 0.001\n","Score:  0.679765330237572\n","Coefficients:  [0.16326228 0.16731439 0.16351531 0.15859281 0.16649824 0.16657605\n"," 0.16306425 0.16737437 0.16928289]\n","Alpha = 0.01\n","Score:  0.6655126663626186\n","Coefficients:  [0.14159091 0.14581789 0.14137704 0.13625125 0.1462931  0.145925\n"," 0.14295352 0.14578453 0.14847301]\n","Alpha = 0.1\n","Score:  0.6529590779053858\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Alpha = 1\n","Score:  0.6529590779053858\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","(0.6814113354616692, 0.0001)\n"]}],"source":["lasso_scores = []\n","\n","for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","\n","    lasso = linear_model.Lasso(alpha = alpha)\n","    lasso.fit(X,y)\n","    y_pred = lasso.predict(X)\n","    score = regr_accuracy(y_pred, y)\n","    print('Score: ', score)\n","    lasso_scores.append((score, alpha))\n","\n","    print('Coefficients: ', lasso.coef_)\n","\n","optimum_lasso = max(lasso_scores, key=lambda x: x[0])\n","print(optimum_lasso)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# from sklearn.linear_model import Lasso\n","# from sklearn.model_selection import GridSearchCV\n","\n","# # Создаем модель Lasso\n","# lasso = Lasso()\n","\n","# # Создаем словарь параметров для GridSearchCV\n","# parameters = {'alpha': [1e-4, 1e-3, 0.01, 0.1, 1]}\n","\n","# # Создаем объект GridSearchCV\n","# lasso_cv = GridSearchCV(lasso, parameters, cv=5)\n","\n","# # Подготавливаем данные\n","# X = X\n","# y = y\n","\n","# # Выполняем подбор параметров\n","# lasso_cv.fit(X, y)\n","\n","# # Выводим оптимальные параметры\n","# print(\"Лучшие параметры: \", lasso_cv.best_params_)\n","# print(\"Лучшая оценка: \", lasso_cv.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"bEtMb7HnqBuK"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"ijIaEpdmqBuK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: lasso\n"]},{"name":"stdout","output_type":"stream","text":["Mean score = 0.68142\n"]}],"source":["lasso = linear_model.Lasso(alpha = optimum_lasso[1])\n","score = train(lasso, 'lasso', regr_accuracy, kf, X, y)\n","scores['lasso'] = score"]},{"cell_type":"markdown","metadata":{"id":"lT6aVlFvqUWP"},"source":["#### **Задание 3** "]},{"cell_type":"markdown","metadata":{"id":"jC4eciIHqBuL"},"source":["Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Ridge**."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"NbCQ_NzuqBuM"},"outputs":[],"source":["# # напишите здесь ваш код\n","# from sklearn.linear_model import Ridge\n","\n","# # Создаем модель Lasso\n","# ridge = Ridge()\n","\n","# # Создаем словарь параметров для GridSearchCV\n","# parameters = {'alpha': [1e-4, 1e-3, 0.01, 0.1, 1]}\n","\n","# # Создаем объект GridSearchCV\n","# from sklearn.model_selection import GridSearchCV\n","# ridge_cv = GridSearchCV(ridge, parameters, cv=5)\n","\n","# # Подготавливаем данные\n","# X = X\n","# y = y\n","\n","# # Выполняем подбор параметров\n","# ridge_cv.fit(X, y)\n","\n","# # Выводим оптимальные параметры\n","# print(\"Лучшие параметры: \", ridge_cv.best_params_)\n","# print(\"Лучшая оценка: \", ridge_cv.best_score_)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha = 0.0001\n","Score:  0.6815995688046768\n","Coefficients:  [0.16568775 0.16971513 0.16597877 0.16106906 0.16872992 0.16885621\n"," 0.16528861 0.16977101 0.17160088]\n","Alpha = 0.001\n","Score:  0.6815995688046768\n","Coefficients:  [0.16568775 0.16971513 0.16597877 0.16106906 0.16872992 0.16885621\n"," 0.16528861 0.16977101 0.17160088]\n","Alpha = 0.01\n","Score:  0.6815995688046768\n","Coefficients:  [0.16568774 0.16971513 0.16597877 0.16106906 0.16872992 0.1688562\n"," 0.16528861 0.169771   0.17160088]\n","Alpha = 0.1\n","Score:  0.6815995688046768\n","Coefficients:  [0.16568772 0.1697151  0.16597874 0.16106904 0.16872989 0.16885617\n"," 0.16528858 0.16977097 0.17160084]\n","Alpha = 1\n","Score:  0.6815995688046768\n","Coefficients:  [0.16568744 0.16971477 0.16597845 0.16106882 0.16872959 0.16885586\n"," 0.16528833 0.16977064 0.17160049]\n","(0.6815995688046768, 0.0001)\n"]}],"source":["ridge_scores = []\n","\n","for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","    ridge = linear_model.Ridge(alpha = alpha)\n","    ridge.fit(X,y)\n","    y_pred = ridge.predict(X)\n","    score = regr_accuracy(y_pred, y)\n","    print('Score: ', score)\n","    ridge_scores.append((score, alpha))\n","    \n","    print('Coefficients: ', ridge.coef_)\n","\n","optimum_ridge = max(ridge_scores, key=lambda x: x[0])\n","print(optimum_ridge)"]},{"cell_type":"markdown","metadata":{"id":"Mx1E56OwqBuM"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"mvicDflUqBuM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: ridge\n","Mean score = 0.68158\n"]}],"source":["ridge = linear_model.Ridge(alpha = optimum_ridge[1])\n","score = train(ridge, 'ridge', regr_accuracy, kf, X, y)\n","scores['ridge'] = score"]},{"cell_type":"markdown","metadata":{"id":"V18B9WFqqBuN"},"source":["Как видим, **Lasso** просто занулила все коэффициенты при $\\alpha>0.01$."]},{"cell_type":"markdown","metadata":{"id":"_bm3DSxiqBuN"},"source":["### Логистическая регрессия"]},{"cell_type":"markdown","metadata":{"id":"Zk3mvsA_qBuO"},"source":["Если на выходе линейной регрессии получается просто вещественное число, то в логистической регрессии это число преобразуется с помощью логистической функции в отрезок \\[0,1\\], а потому может трактоваться как вероятность получения на выходе дискретного значения 1. \n","\n","$$f(y)=\\dfrac{1}{1+e^{-y}}$$\n","\n","Таким образом, модель логистической регрессии может успешно использоваться как бинарный классификатор. Логистическая регрессия минимизирует следующую величину (L1 и L2 регуляризация уже включены и контролируются параметрами $C$ - \"сила\" регуляризации (малые значения - \"сильная\" регуляризация), $\\rho$ - относительный вклад L1-регуляризации):\n","\n","$$\\min_{w, c} \\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1)$$\n","\n","Создадим модель **[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression 'Logistic Regression')** и обучим ее.\n","\n","Подберите оптимальное значение параметра регуляризации **С** и тип регуляризации **penalty**. "]},{"cell_type":"markdown","metadata":{"id":"N5CGOf2GqeeK"},"source":["#### **Задание 4** "]},{"cell_type":"code","execution_count":34,"metadata":{"id":"1P4VdrGSqBuP"},"outputs":[{"name":"stdout","output_type":"stream","text":["C = 0.0001, penalty = l2\n","Score:  0.6815987395829014\n","Coefficients:  [[0.94428564 0.95527404 0.9428829  0.92846392 0.95544762 0.95217514\n","  0.94471166 0.957817   0.96358774]]\n","C = 0.0001, penalty = None\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6815987395829014\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","C = 0.001, penalty = l2\n","Score:  0.6815987395829014\n","Coefficients:  [[1.23401978 1.25356599 1.23296359 1.2058224  1.24583208 1.24106652\n","  1.22359951 1.26161396 1.26817165]]\n","C = 0.001, penalty = None\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6815987395829014\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","C = 0.01, penalty = l2\n","Score:  0.6815987395829014\n","Coefficients:  [[1.28680973 1.30838514 1.28591942 1.25560501 1.29838991 1.29332568\n","  1.27324397 1.31795508 1.32458075]]\n","C = 0.01, penalty = None\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6815987395829014\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","C = 0.1, penalty = l2\n","Score:  0.6815987395829014\n","Coefficients:  [[1.29261472 1.31442328 1.29174479 1.26106248 1.30416168 1.29906324\n","  1.27867651 1.32417199 1.33080472]]\n","C = 0.1, penalty = None\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\alex\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Score:  0.6815987395829014\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","C = 1, penalty = l2\n","Score:  0.6815987395829014\n","Coefficients:  [[1.29320118 1.31503341 1.29233334 1.26161364 1.30474469 1.29964278\n","  1.27922504 1.32480032 1.33143375]]\n","C = 1, penalty = None\n","Score:  0.6815987395829014\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","(0.6815987395829014, 'l2', 0.0001)\n"]}],"source":["logistic_scores = []\n","\n","for C in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    for penalty in ['l2', None]:\n","        print(f'C = {C}, penalty = {penalty}')\n","\n","        logistic = linear_model.LogisticRegression(penalty=penalty, C=C)\n","        logistic.fit(X,y)\n","        y_pred = ridge.predict(X)\n","        score = regr_accuracy(y_pred, y)\n","        print('Score: ', score)\n","        logistic_scores.append((score, penalty, C))\n","    \n","        print('Coefficients: ', logistic.coef_)\n","\n","optimum_logistic = max(logistic_scores, key=lambda x: x[0])\n","print(optimum_logistic)"]},{"cell_type":"markdown","metadata":{"id":"IW1aI40TqBuP"},"source":["Обучим модель с оптимальным значением параметра **С**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"cctaYPAcqBuP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: logistic regression\n","Mean score = 0.83619\n"]}],"source":["logistic_regr = linear_model.LogisticRegression(penalty = optimum_logistic[1], C=optimum_logistic[2], solver='lbfgs')\n","score = train(logistic_regr, 'logistic regression', class_accuracy, kf, X, y)\n","scores['logistic regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"wYfkTsd0qBuQ"},"source":["## Метод опорных векторов"]},{"cell_type":"markdown","metadata":{"id":"NdFpL7e3qBuQ"},"source":["Этот метод применим для решения как задач классификации, так и регрессии, и кластеризации. Основными достоинствами метода являются:\n","\n","- эффективность при большой размерности пространства признаков\n","- в процессе обучения запоминается только подвыборка обучающей выборки - опорные вектора, т.е. требует меньший объем памяти\n","- можно применять разные ядра (kernels) для формирования модели\n","\n","Недостатком метода опорных векторов является то, что в случае, когда размерность пространства признаков много больше объема обучающей выборки, на результат работы модели сильно влияет выбор ядра. Также этот метод не позволяет быстро и просто получить вероятность прогноза.\n","\n","С математической точки зрения, метод опорных векторов проводит гипер-плоскость, которая разделяет один класс от другого. При этом граница проводится так, что быть расположенной максимально далеко от каждой из точек.\n","![SVC](https://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png)\n","\n","Функция ядра определяет, какие признаки будут использоваться в качестве переменных в гиперпространстве, в котором проводится гипер-плоскость. Например, для линейного ядра $\\langle x, x'\\rangle$ берутся исходные признаки, для полиномиального ядра - полиномы от исходных признаков $(\\gamma \\langle x, x'\\rangle + r)^d$, для radial-basis-function (rbf) - экспоненциальная функция $\\exp(-\\gamma \\|x-x'\\|^2)$.\n","\n","Построим модель Support Vector Classifier - [**SVC**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC 'SVC') для различных ядер. Заранее уменьшим размер выборки, что позволит проводить обучения в разумное время (метод опорных векторов довольно долго обучается).\n","\n","Определите оптимальное значение параметра регуляризации **С** и типа ядра **kernel**."]},{"cell_type":"markdown","metadata":{"id":"ivF5OJxVqhSq"},"source":["#### **Задание 5**"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"r0bgmnaoqBuR"},"outputs":[{"name":"stdout","output_type":"stream","text":["C = 0.0001, kernel = linear\n","Score:  0.6497\n","C = 0.0001, kernel = poly\n","Score:  0.6497\n","C = 0.0001, kernel = rbf\n","Score:  0.6497\n","C = 0.0001, kernel = sigmoid\n","Score:  0.6497\n","C = 0.001, kernel = linear\n","Score:  0.8129\n","C = 0.001, kernel = poly\n","Score:  0.6497\n","C = 0.001, kernel = rbf\n","Score:  0.6497\n","C = 0.001, kernel = sigmoid\n","Score:  0.6497\n","C = 0.01, kernel = linear\n","Score:  0.8305\n","C = 0.01, kernel = poly\n","Score:  0.725\n","C = 0.01, kernel = rbf\n","Score:  0.8278\n","C = 0.01, kernel = sigmoid\n","Score:  0.8207\n","C = 0.1, kernel = linear\n","Score:  0.8311\n","C = 0.1, kernel = poly\n","Score:  0.8072\n","C = 0.1, kernel = rbf\n","Score:  0.8421\n","C = 0.1, kernel = sigmoid\n","Score:  0.8308\n","C = 1, kernel = linear\n","Score:  0.8316\n","C = 1, kernel = poly\n","Score:  0.8291\n","C = 1, kernel = rbf\n","Score:  0.8459\n","C = 1, kernel = sigmoid\n","Score:  0.8242\n"]}],"source":["from sklearn.svm import SVC\n","X_svc = X.iloc[:10000, :]\n","y_svc = y[:10000]\n","\n","scores_svc = []\n","\n","for C in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n","        print(f'C = {C}, kernel = {kernel}')\n","        svc = SVC(C=C, kernel=kernel, gamma='auto')\n","        svc.fit(X_svc, y_svc)\n","        y_pred = svc.predict(X_svc)\n","        score = regr_accuracy(y_pred, y_svc)\n","        scores_svc.append((score, C, kernel))\n","        print('Score: ', score)\n","\n","# напишите здесь ваш код"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.8459, 1, 'rbf')\n"]}],"source":["optimum_svc = max(scores_svc, key=lambda x: x[0])\n","print(optimum_svc)"]},{"cell_type":"markdown","metadata":{"id":"sfsLap6cqBuR"},"source":["Обучим модель с оптимальным значением параметра **С** и типом ядра **kernel**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"scitVGNbqBuS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: svc\n"]},{"name":"stdout","output_type":"stream","text":["Mean score = 0.84210\n"]}],"source":["svc = SVC(C=optimum_svc[1], kernel=optimum_svc[2], gamma='auto')\n","score = train(svc, 'svc', class_accuracy, kf, X_svc, y_svc)\n","scores['svc'] = score"]},{"cell_type":"markdown","metadata":{"id":"VNehNP8gqBuS"},"source":["## Дерево решений"]},{"cell_type":"markdown","metadata":{"id":"UP-bW4hwqBuS"},"source":["В модели дерева решений (Decision Tree) в процессе обучения строится алгоритм, по которому выполняется прогноз модели. При этом алгоритм представляет из себя дерево, каждый лист которого - это проверка на то, что какой-либо признак из обучающей выборки принимает определенное значение. Пример дерева решений приведен на рисунке ниже.\n","![Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png)\n","\n","Преимуществами такого метода являются:\n","- простота визуализации и хорошая интерпретируемость алгоритма прогноза\n","- не требуется нормализация данных\n","- скорость прогноза пропорциональна логарифму объема выборки, т.е. этот метод быстрый\n","- может обрабатывать как числовые, так и категориальные данные\n","\n","Недостатками метода являются:\n","- деревья легко переобучаются\n","- небольшие изменения в обучающей выборке могут привести к перестойке всего дерева, т.е. метод нестабилен\n","- предсказания деревьев являются кусочно-постоянными, поэтому не годятся для экстраполирования\n","- требуется сбалансировать обучающую выборку по классам, чтобы не допустить \"перекоса\" дерева в сторону какого-либо класса\n","\n","Конкретную математическую реализалицаю алгоритма построения дерева решений можно изучить, например, [здесь.](https://scikit-learn.org/stable/modules/tree.html)\n","\n","Создадим модель [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier 'DecisionTreeClassifier') и обучим ее. Для того, чтобы предотвратить переобучение дерева, обычно ограничивается максимальная глубина дерева - параметр **max_depth**, а также минимальное число элементов из обучающей выборки, приходящееся на определнный лист, чтобы можно было с него сделать новое ветвление - параметр **min_samples_split**.\n","\n","Подберите оптимальное значение параметров **max_depth** и **min_samples_split**."]},{"cell_type":"markdown","metadata":{"id":"3dc10J6-qq_P"},"source":["#### **Задание 6** "]},{"cell_type":"code","execution_count":39,"metadata":{"id":"DSShPADxqBuT"},"outputs":[{"name":"stdout","output_type":"stream","text":["max_depth = 1, min_samples_split = 2\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 12\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 23\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 34\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 45\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 56\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 67\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 78\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 89\n","Score:  0.7470226792155562\n","max_depth = 1, min_samples_split = 100\n","Score:  0.7470226792155562\n","max_depth = 12, min_samples_split = 2\n","Score:  0.7937227911604958\n","max_depth = 12, min_samples_split = 12\n","Score:  0.7950138894647374\n","max_depth = 12, min_samples_split = 23\n","Score:  0.792485592271653\n","max_depth = 12, min_samples_split = 34\n","Score:  0.7937999087856047\n","max_depth = 12, min_samples_split = 45\n","Score:  0.7968124714955015\n","max_depth = 12, min_samples_split = 56\n","Score:  0.7968945644512625\n","max_depth = 12, min_samples_split = 67\n","Score:  0.8016261039014885\n","max_depth = 12, min_samples_split = 78\n","Score:  0.7980753762593805\n","max_depth = 12, min_samples_split = 89\n","Score:  0.8019934491479747\n","max_depth = 12, min_samples_split = 100\n","Score:  0.8093088436502343\n","max_depth = 23, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 23, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 23, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 23, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 23, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 23, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 23, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 23, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 23, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 23, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 34, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 34, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 34, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 34, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 34, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 34, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 34, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 34, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 34, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 34, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 45, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 45, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 45, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 45, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 45, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 45, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 45, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 45, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 45, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 45, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 56, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 56, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 56, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 56, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 56, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 56, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 56, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 56, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 56, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 56, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 67, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 67, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 67, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 67, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 67, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 67, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 67, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 67, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 67, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 67, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 78, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 78, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 78, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 78, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 78, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 78, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 78, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 78, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 78, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 78, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 89, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 89, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 89, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 89, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 89, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 89, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 89, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 89, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 89, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 89, min_samples_split = 100\n","Score:  0.8090252498030598\n","max_depth = 100, min_samples_split = 2\n","Score:  0.7881122766283842\n","max_depth = 100, min_samples_split = 12\n","Score:  0.7868294705418964\n","max_depth = 100, min_samples_split = 23\n","Score:  0.7916712964882457\n","max_depth = 100, min_samples_split = 34\n","Score:  0.7919789377669058\n","max_depth = 100, min_samples_split = 45\n","Score:  0.7957643351714416\n","max_depth = 100, min_samples_split = 56\n","Score:  0.7976947634644885\n","max_depth = 100, min_samples_split = 67\n","Score:  0.8014096770181185\n","max_depth = 100, min_samples_split = 78\n","Score:  0.7985745677681496\n","max_depth = 100, min_samples_split = 89\n","Score:  0.8033326423151872\n","max_depth = 100, min_samples_split = 100\n","Score:  0.8090252498030598\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","scores_dtc = []\n","\n","X_dtc = X.iloc[:10000, :]\n","y_dtc = y[:10000]\n","\n","for max_depth in np.linspace(1, 100, 10, endpoint=True, dtype=int):\n","    for min_samples_split in np.linspace(2, 100, 10, endpoint=True, dtype=int):\n","        print(f'max_depth = {max_depth}, min_samples_split = {min_samples_split}')\n","        dtc = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=1, random_state=0)\n","        dtc.fit(X_dtc, y_dtc)\n","        y_pred = dtc.predict(X)\n","        score = regr_accuracy(y_pred, y)\n","        scores_dtc.append((score, max_depth, min_samples_split))\n","        print('Score: ', score)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"pQExOWvOqBuT"},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.8093088436502343, 12, 100)\n"]}],"source":["optimum_dtc = max(scores_dtc, key=lambda x: x[0])\n","print(optimum_dtc)"]},{"cell_type":"markdown","metadata":{"id":"NJB7z7RiqBuU"},"source":["Создадим модель с оптимальными значениями параметров **max_depth** и **min_samples_split**. Добавим ее в словарь **scores**."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"STjh7rAuqBuU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: decision tree\n"]},{"name":"stdout","output_type":"stream","text":["Mean score = 0.85644\n"]}],"source":["dtc = DecisionTreeClassifier(max_depth=optimum_dtc[1], min_samples_split=optimum_dtc[2], min_samples_leaf=1, random_state=0)\n","score = train(dtc, 'decision tree', class_accuracy, kf, X, y)\n","scores['decision tree'] = score"]},{"cell_type":"markdown","metadata":{"id":"L54zzd7KqBuU"},"source":["## Сравнение различных моделей"]},{"cell_type":"markdown","metadata":{"id":"xEaMPqy-qBuU"},"source":["Отобразим на графике точность работы каждой построенной модели. Для этого будем использовать значения из словаря **scores**."]},{"cell_type":"code","execution_count":42,"metadata":{"id":"b6SRzljXqBuV"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(10,5))\n","xx = list(scores.keys())\n","yy = list(scores.values())\n","rects = plt.bar(xx, yy)\n","plt.ylim(0.6, 0.9)\n","plt.ylabel('Accuracy')\n","for i, rect in enumerate(rects):\n","    yloc = rect.get_height()\n","    xloc = rect.get_x() + rect.get_width() / 4\n","    plt.annotate(round(yy[i], 4), xy=(xloc, yloc), xytext=(xloc, 10),\n","                            textcoords=\"offset points\",\n","                            va='center',\n","                            color='black', clip_on=True)"]},{"cell_type":"markdown","metadata":{"id":"mFqOwK_mqBuV"},"source":["# Выводы"]},{"cell_type":"markdown","metadata":{"id":"u_haAZPuqwqf"},"source":["#### **Задание 7** "]},{"cell_type":"markdown","metadata":{"id":"XXjkE-WUqBuV"},"source":["Напишите выводы по лабораторной работе"]},{"cell_type":"markdown","metadata":{},"source":["Мы получили следующие результаты:\n","\n","Модели в порядке возрастания точности: lasso, linear regression, ridge, logistic regression, svc, decision tree.\n","\n","Метод linear regression является самым простым.\n","\n","Методы decision tree, svc, хотя и являются самыми точными из примененных, занимают большее\n","время на обучение, чем остальные."]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
