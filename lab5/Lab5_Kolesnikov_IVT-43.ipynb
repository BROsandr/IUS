{"cells":[{"cell_type":"markdown","metadata":{"id":"_DsfDI6DqBtO"},"source":["# Лабораторная работа № 5. Решение задачи классификации на примере прогноза состояния системы на основе данных о состоянии ее компонентов."]},{"cell_type":"markdown","metadata":{"id":"VmbTnG0-qBtc"},"source":["В работе проводится ознакомление с различными методами машинного обучения с учителем, решающих задачу классификации. СОздаются различные линейные и нелинейные модели и оценивается точность из прогноза."]},{"cell_type":"markdown","metadata":{"id":"aV2fRv3aqBtg"},"source":["## Введение"]},{"cell_type":"markdown","metadata":{"id":"EjyHwi_EqBti"},"source":["Современные радиолокационные станции (РЛС) – это структурно-сложные радиотехнические и информационные системы, характеризующиеся высокой надежностью функционирования и большим числом цифровых компонентов в своем составе. Одним из таких компонентов является блок усиления мощности (БУМ), задача которого усиливать передаваемый или принимаемый сигнал.\n","\n","Функционирование БУМ приводит к их нагреву, что может сказаться на снижении их работоспособности или даже привести к отказу. Под системой в этой работе мы будем понимать несколько БУМ, объединенных в единое целое. Тогда техническое состояние всей системы будет определяться техническим состоянием ее компонент, т.е. состоянием БУМ в данной работе. Техническое же состояние БУМ напрямую зависит от их температуры: при достижении определенного порога блок перестает работать и начинает охлаждаться. После охлаждения до определенной температуры он снова переходит в рабоспособное состояние.\n","\n","Основная задача - спрогнозировать увеличение температуры блоков усиления мощности на основании истории их функционирования и режима работы блоков, который задает интенсивность нагрева, и возможный выход из строя всей системы блоков. В лабораторной работе № 3 проводится статистический анализ данных тепловой нагрузки модельных БУМ, определяются пороговые значения температур, при которых происходит отключение блоков с целью их охлаждения. На основании пороговых температур вычислено состояние блоков в интервале \\[0, 1\\] и установлен простой критерий определения состояния системы - снижение среднего состояния всех блоков ниже определенного порогового значения. \n","\n","В данной лабораторной работе будут применены различные методы машинного обучения с учителем для установления зависимости состояния системы от состояний блоков и прогноза состояния системы."]},{"cell_type":"markdown","metadata":{"id":"_S9KJFqHqBtm"},"source":["## Описание исходных данных"]},{"cell_type":"markdown","metadata":{"id":"u4j3rBTXqBto"},"source":["Подключим стандартные пакеты для работы с данными и построения графиков"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"gjwqQJm5qBtq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5Ed3QNatqBtw"},"source":["Загрузим файл с данными и выведем на экран первые 5 строк. Получим информацию по каждой колонке."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sxSFtxYEqBty"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Lab4_data.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32me:\\work\\vuz\\IUS\\IUS\\lab5\\Lab5_Kolesnikov_IVT-43.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_Kolesnikov_IVT-43.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mLab4_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/work/vuz/IUS/IUS/lab5/Lab5_Kolesnikov_IVT-43.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Lab4_data.csv'"]}],"source":["df = pd.read_csv(\"Lab5_data.csv\")\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKlxfuswqBt1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1205950 entries, 0 to 1205949\n","Data columns (total 10 columns):\n"," #   Column        Non-Null Count    Dtype  \n","---  ------        --------------    -----  \n"," 0   state1        1205950 non-null  float64\n"," 1   state2        1205950 non-null  float64\n"," 2   state3        1205950 non-null  float64\n"," 3   state4        1205950 non-null  float64\n"," 4   state5        1205950 non-null  float64\n"," 5   state6        1205950 non-null  float64\n"," 6   state7        1205950 non-null  float64\n"," 7   state8        1205950 non-null  float64\n"," 8   state9        1205950 non-null  float64\n"," 9   system_state  1205950 non-null  float64\n","dtypes: float64(10)\n","memory usage: 92.0 MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"VgrvAO1VqBt2"},"source":["Колонки **state1 - state9** содержат состояние блока 1 - 9 в виде вещественного числа в интервале \\[0, 1\\]. При этом значению 1 соответствует работоспособное состояние с минимальной температурой, в состоянию 0 - выключенное состояние, когда блок находится в режиме обхлаждения. Колонка **system_state** обозначает состояние системы: 1 - работоспособна, 0 - нерабоспособна. Все колонки имеют тип **float64**."]},{"cell_type":"markdown","metadata":{"id":"mt-LyBPmqBt4"},"source":["## Подготовка данных"]},{"cell_type":"markdown","metadata":{"id":"uIKiNU2qqBt5"},"source":["Для использования моделей машинного обучения с учителем необходимо специальным образом подготовить данные: сформировать обучающую выборку, на которой модель будет \"учиться\", т.е. подстраивать свои внутренние параметры, тестовую выборку, на которой будет определяться точность модели в процессе ее обучения, а также валидационную выборку, на которой проверяется итогое качество работы модели. \n","\n","Вместо выделения валидационной выборки можно использовать механизм кросс-валидации.В основе метода лежит разделение исходного множества данных на **k** примерно равных блоков, например 5. Затем на **k-1**, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется **k** раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.\n","![Cross-validation](https://wiki.loginom.ru/images/cross-validation.svg)"]},{"cell_type":"markdown","metadata":{"id":"L-clFbuQqBt7"},"source":["Кросс-валидация имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели:\n","\n","- Распределение классов оказывается более равномерным, что улучшает качество обучения.\n","- Если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная оценка будет более достоверной.\n","\n","В дальнейшем в этой лабораторной работе будем использовать разбиение на 5 блоков с помощью метода **[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=k%20fold#sklearn.model_selection.KFold 'KFold')**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbvqQcwKqBt9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","Train index:  [      0       2       4 ... 1205947 1205948 1205949]\n","Test index:  [      1       3       8 ... 1205927 1205945 1205946]\n","Fold 2\n","Train index:  [      0       1       2 ... 1205946 1205947 1205948]\n","Test index:  [      5       6       7 ... 1205940 1205941 1205949]\n","Fold 3\n","Train index:  [      0       1       2 ... 1205947 1205948 1205949]\n","Test index:  [      4       9      11 ... 1205930 1205933 1205939]\n","Fold 4\n","Train index:  [      1       3       4 ... 1205947 1205948 1205949]\n","Test index:  [      0       2      10 ... 1205932 1205936 1205943]\n","Fold 5\n","Train index:  [      0       1       2 ... 1205945 1205946 1205949]\n","Test index:  [     12      13      16 ... 1205944 1205947 1205948]\n"]}],"source":["from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5, shuffle=True)\n","X = df.loc[:, 'state1':'state9']\n","y = df['system_state'].astype(int)\n","\n","for i, (train_index, test_index) in enumerate(kf.split(X), start=1):\n","    print('Fold {}'.format(i))\n","    print('Train index: ', train_index)\n","    print('Test index: ', test_index)"]},{"cell_type":"markdown","metadata":{"id":"EJuzMzGlqBt_"},"source":["## Линейные модели машинного обучения"]},{"cell_type":"markdown","metadata":{"id":"_LeJCG4YqBt_"},"source":["Задача определения состояния системы по известным состояниям блоков является задачей бинарной классификации. Среди линейных моделей будем использовать линейную регрессию, линейную регрессию с L1 и L2-регуляризацией, а также логистическую регрессию. Подробное описание работы этих моделей можно прочитать на сайте [Scikit Learn](https://scikit-learn.org/stable/modules/linear_model.html 'Scikit Learn')."]},{"cell_type":"markdown","metadata":{"id":"4q9msIwFqEL8"},"source":["#### **Задание 1** "]},{"cell_type":"markdown","metadata":{"id":"gR_4Iew-qBuB"},"source":["Сделаем процесс обучения различных моделей универсальным. Для этого напишем функцию **regr_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели регрессии, функцию **class_accuracy(y_pred, y_test)**, которая будет считать точность спрогнизорованных значений целевой переменной для модели классификации, и функцию **train(model, model_name, evaluate, kfold, X, y)**, которая обучает заданную модель **model** с использованием механизма кросс-валидации **kfold**.\n","\n","Точность - относительная доля правильно спрогнозированных значений."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XlMFRASqBuC"},"outputs":[],"source":["def regr_accuracy(y_pred, y_test):\n","    match=0\n","    for i in range(len(y_test)):\n","        if(y_pred[i]==y_test[i]):\n","            match+=1\n","    return match/len(y_test)\n","    \n","\n","def class_accuracy(y_pred, y_test):\n","    match=0\n","    for i in range(len(y_test)):\n","        if(y_pred[i]==y_test[i]):\n","            match+=1\n","    return match/len(y_test)\n","\n","def train(model, model_name, evaluate, kfold, X, y):\n","\n","    print('Train model: '+model_name)\n","    scores = []\n","    for train_index, test_index in kfold.split(X):\n","        \n","        X_train, X_test = X.values[train_index], X.values[test_index]\n","        y_train, y_test = y.values[train_index], y.values[test_index]\n","        model.fit(X_train,y_train)\n","        pred = model.predict(X_test).astype(int)\n","        scores.append(evaluate(pred, y_test))\n","        \n","    mean_score = np.mean(scores)\n","    print('Mean score = {:.5f}'.format(mean_score))\n","    return mean_score"]},{"cell_type":"markdown","metadata":{"id":"B5yEVTk8qBuE"},"source":["### Линейная регрессия"]},{"cell_type":"markdown","metadata":{"id":"o1LF2lQXqBuF"},"source":["В линейных моделях целевая переменная $\\hat{y}$ определяется как линейная комбинация известных переменных (признаков):\n","\n","$$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n","\n","В модели линейной регрессии коэффициенты $w = (w_1, ..., w_p)$ подбираются таким образом, чтобы минимизировать сумму квадратов отклонений рассчитанных значений целевой переменной от истинных значений:\n","\n","$$\\min_{w} || X w - y||_2^2$$\n","\n","Важно отметить, что линейные модели чувствительны к абсолютным значениям признаков, поэтому следует перед применением линейных моделей провести нормирование исходных данных (обычно на интервал \\[0,1\\]). Также применение линейных моделей основано на предположении о линейной независимости признаков, поэтому следует стараться не использовать в качестве признаков коррелированные признаки. В противном случае модель будет чувствительна к шумам, т.е. случайным выбросам в значениях признаков."]},{"cell_type":"markdown","metadata":{"id":"ZrfRKpNhqBuG"},"source":["Создадим и обучим модель **[LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression 'LinearRegression')**. Запишем точность модели в словарь **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1yueQNJqBuH"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: linear regression\n","Mean score = 0.68160\n"]}],"source":["from sklearn import linear_model\n","\n","lin_reg = linear_model.LinearRegression()\n","\n","scores = dict()\n","\n","score = train(lin_reg, 'linear regression', regr_accuracy, kf, X, y)\n","scores['linear regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"8SOVicj5qBuI"},"source":["### Линейная регрессия c L1 и L2 регуляризацией"]},{"cell_type":"markdown","metadata":{"id":"DGNWt1qDqBuJ"},"source":["Если размер обучающей выборки невелик, а число признаков, наоборот, достаточно велико, то коэффициенты модели могут быть подобраны таким образом, чтобы модель максимально точно учитывала все точки из обучающей выборки, при этом вне обучающей выборки модель будет давать большую ошибку. Это явление носит название переобучения. Одним из способов препятствовать переобучению является механизмы регуляризации. Он ограничивает значения коэффицентов $w = (w_1, ..., w_p)$, используемых в модели.\n","\n","L1-регуляризация вносит дополнительный \"штраф\", пропорциональный модулю значения коэффициента:\n","$$\\min_{w} ||X w - y||_2 ^ 2 + \\alpha ||w||_1$$\n","\n","L2-регуляризация вносит дополнительный \"штраф\", пропорциональный квадрату модуля значения коэффициента:\n","$$\\min_{w} || X w - y||_2^2 + \\alpha ||w||_2^2$$\n","\n","Параметр $\\alpha$ задает \"силу\" регуляризации. L1-регуляризация приведет к тому, что все несущественные признаки будут иметь вес, равный 0. L2-регуляризация приведет к тому, что несущественные признаки будут иметь околонулевые веса. Продемонстрируем это на примере. Создадим и обучим модели **[Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso 'Lasso')** (L1-регуляризация) и **[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge 'Ridge')** (L2-регуляризация).\n","\n","Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Lasso**."]},{"cell_type":"markdown","metadata":{"id":"WA9AmWF9qRZ4"},"source":["#### **Задание 2** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbZqmJWUqBuJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha = 0.0001\n","Coefficients:  [0.16542942 0.16946404 0.16572914 0.16082697 0.16851875 0.16864115\n"," 0.16507533 0.16953335 0.17136388]\n","Alpha = 0.001\n","Coefficients:  [0.16326228 0.16731439 0.16351531 0.15859281 0.16649824 0.16657605\n"," 0.16306425 0.16737437 0.16928289]\n","Alpha = 0.01\n","Coefficients:  [0.14159091 0.14581789 0.14137704 0.13625125 0.1462931  0.145925\n"," 0.14295352 0.14578453 0.14847301]\n","Alpha = 0.1\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Alpha = 1\n","Coefficients:  [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","    lasso = linear_model.Lasso(alpha = alpha)\n","    lasso.fit(X,y)\n","    \n","    # напишите здесь ваш код\n","    \n","    print('Coefficients: ', lasso.coef_)"]},{"cell_type":"markdown","metadata":{"id":"bEtMb7HnqBuK"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijIaEpdmqBuK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: lasso\n","Mean score = 0.68141\n"]}],"source":["lasso = linear_model.Lasso(alpha = 0.0001)\n","score = train(lasso, 'lasso', regr_accuracy, kf, X, y)\n","scores['lasso'] = score"]},{"cell_type":"markdown","metadata":{"id":"lT6aVlFvqUWP"},"source":["#### **Задание 3** "]},{"cell_type":"markdown","metadata":{"id":"jC4eciIHqBuL"},"source":["Подберите оптимальное значения параметра регуляризации **$\\alpha$** для модели **Ridge**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbCQ_NzuqBuM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alpha = 0.0001\n","Coefficients:  [0.16568775 0.16971513 0.16597877 0.16106906 0.16872992 0.16885621\n"," 0.16528861 0.16977101 0.17160088]\n","Alpha = 0.001\n","Coefficients:  [0.16568775 0.16971513 0.16597877 0.16106906 0.16872992 0.16885621\n"," 0.16528861 0.16977101 0.17160088]\n","Alpha = 0.01\n","Coefficients:  [0.16568774 0.16971513 0.16597877 0.16106906 0.16872992 0.1688562\n"," 0.16528861 0.169771   0.17160088]\n","Alpha = 0.1\n","Coefficients:  [0.16568772 0.1697151  0.16597874 0.16106904 0.16872989 0.16885617\n"," 0.16528858 0.16977097 0.17160084]\n","Alpha = 1\n","Coefficients:  [0.16568744 0.16971477 0.16597845 0.16106882 0.16872959 0.16885586\n"," 0.16528833 0.16977064 0.17160049]\n"]}],"source":["for alpha in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","    print('Alpha = {}'.format(alpha))\n","    ridge = linear_model.Ridge(alpha = alpha)\n","    ridge.fit(X.values,y.values)\n","    # напишите здесь ваш код\n","    \n","    print('Coefficients: ', ridge.coef_)"]},{"cell_type":"markdown","metadata":{"id":"Mx1E56OwqBuM"},"source":["Обучим модель с оптимальным значением параметра $\\alpha$. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvicDflUqBuM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: ridge\n","Mean score = 0.68159\n"]}],"source":["ridge = linear_model.Ridge(alpha = 0.0001)\n","score = train(ridge, 'ridge', regr_accuracy, kf, X, y)\n","scores['ridge'] = score"]},{"cell_type":"markdown","metadata":{"id":"V18B9WFqqBuN"},"source":["Как видим, **Lasso** просто занулила все коэффициенты при $\\alpha>0.01$."]},{"cell_type":"markdown","metadata":{"id":"_bm3DSxiqBuN"},"source":["### Логистическая регрессия"]},{"cell_type":"markdown","metadata":{"id":"Zk3mvsA_qBuO"},"source":["Если на выходе линейной регрессии получается просто вещественное число, то в логистической регрессии это число преобразуется с помощью логистической функции в отрезок \\[0,1\\], а потому может трактоваться как вероятность получения на выходе дискретного значения 1. \n","\n","$$f(y)=\\dfrac{1}{1+e^{-y}}$$\n","\n","Таким образом, модель логистической регрессии может успешно использоваться как бинарный классификатор. Логистическая регрессия минимизирует следующую величину (L1 и L2 регуляризация уже включены и контролируются параметрами $C$ - \"сила\" регуляризации (малые значения - \"сильная\" регуляризация), $\\rho$ - относительный вклад L1-регуляризации):\n","\n","$$\\min_{w, c} \\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1)$$\n","\n","Создадим модель **[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression 'Logistic Regression')** и обучим ее.\n","\n","Подберите оптимальное значение параметра регуляризации **С** и тип регуляризации **penalty**. "]},{"cell_type":"markdown","metadata":{"id":"N5CGOf2GqeeK"},"source":["#### **Задание 4** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1P4VdrGSqBuP"},"outputs":[{"name":"stdout","output_type":"stream","text":["С = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","С = 0.001\n"]},{"name":"stderr","output_type":"stream","text":["d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","С = 0.01\n"]},{"name":"stderr","output_type":"stream","text":["d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","С = 0.1\n"]},{"name":"stderr","output_type":"stream","text":["d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","С = 1\n","Coefficients:  [[1.29326641 1.31510127 1.2923988  1.26167494 1.30480954 1.29970724\n","  1.27928605 1.32487021 1.33150372]]\n","С = 0.0001\n","Coefficients:  [[0.94428564 0.95527404 0.9428829  0.92846392 0.95544762 0.95217514\n","  0.94471166 0.957817   0.96358774]]\n","С = 0.001\n","Coefficients:  [[1.23401978 1.25356599 1.23296359 1.2058224  1.24583208 1.24106652\n","  1.22359951 1.26161396 1.26817165]]\n","С = 0.01\n","Coefficients:  [[1.28680973 1.30838514 1.28591942 1.25560501 1.29838991 1.29332568\n","  1.27324397 1.31795508 1.32458075]]\n","С = 0.1\n","Coefficients:  [[1.29261472 1.31442328 1.29174479 1.26106248 1.30416168 1.29906324\n","  1.27867651 1.32417199 1.33080472]]\n","С = 1\n","Coefficients:  [[1.29320118 1.31503341 1.29233334 1.26161364 1.30474469 1.29964278\n","  1.27922504 1.32480032 1.33143375]]\n"]}],"source":["for pen in {'l2', 'none'}:\n","    for с in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","        print('С = {}'.format(с))\n","        logistic_regr = linear_model.LogisticRegression(penalty = pen, C=с, solver='lbfgs')\n","        logistic_regr.fit(X.values, y.values, sample_weight=None)\n","        \n","        print('Coefficients: ', logistic_regr.coef_)"]},{"cell_type":"markdown","metadata":{"id":"IW1aI40TqBuP"},"source":["Обучим модель с оптимальным значением параметра **С**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cctaYPAcqBuP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: logistic regression\n","Mean score = 0.83746\n"]}],"source":["logistic_regr = linear_model.LogisticRegression(penalty = 'l2', C=0.001, solver='lbfgs')\n","score = train(logistic_regr, 'logistic regression', class_accuracy, kf, X, y)\n","scores['logistic regression'] = score"]},{"cell_type":"markdown","metadata":{"id":"wYfkTsd0qBuQ"},"source":["## Метод опорных векторов"]},{"cell_type":"markdown","metadata":{"id":"NdFpL7e3qBuQ"},"source":["Этот метод применим для решения как задач классификации, так и регрессии, и кластеризации. Основными достоинствами метода являются:\n","\n","- эффективность при большой размерности пространства признаков\n","- в процессе обучения запоминается только подвыборка обучающей выборки - опорные вектора, т.е. требует меньший объем памяти\n","- можно применять разные ядра (kernels) для формирования модели\n","\n","Недостатком метода опорных векторов является то, что в случае, когда размерность пространства признаков много больше объема обучающей выборки, на результат работы модели сильно влияет выбор ядра. Также этот метод не позволяет быстро и просто получить вероятность прогноза.\n","\n","С математической точки зрения, метод опорных векторов проводит гипер-плоскость, которая разделяет один класс от другого. При этом граница проводится так, что быть расположенной максимально далеко от каждой из точек.\n","![SVC](https://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png)\n","\n","Функция ядра определяет, какие признаки будут использоваться в качестве переменных в гиперпространстве, в котором проводится гипер-плоскость. Например, для линейного ядра $\\langle x, x'\\rangle$ берутся исходные признаки, для полиномиального ядра - полиномы от исходных признаков $(\\gamma \\langle x, x'\\rangle + r)^d$, для radial-basis-function (rbf) - экспоненциальная функция $\\exp(-\\gamma \\|x-x'\\|^2)$.\n","\n","Построим модель Support Vector Classifier - [**SVC**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC 'SVC') для различных ядер. Заранее уменьшим размер выборки, что позволит проводить обучения в разумное время (метод опорных векторов довольно долго обучается).\n","\n","Определите оптимальное значение параметра регуляризации **С** и типа ядра **kernel**."]},{"cell_type":"markdown","metadata":{"id":"ivF5OJxVqhSq"},"source":["#### **Задание 5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0bgmnaoqBuR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Kernel: sigmoid\n","C = 0.0001\n","Coefficients:  [[0.06651126 0.06478033 0.05949256 0.06614627 0.05101285 0.07316202\n","  0.06274074 0.05585116 0.06117923]]\n","C = 0.001\n","Coefficients:  [[0.46890885 0.44807214 0.40243314 0.44816947 0.32406622 0.50951894\n","  0.43386823 0.36965919 0.39665788]]\n","C = 0.01\n","Coefficients:  [[0.91450745 0.81739113 0.7384349  0.78967105 0.49912002 1.00538395\n","  0.84357146 0.63349725 0.49461855]]\n","C = 0.1\n","Coefficients:  [[1.14775898 0.93280561 0.91078082 0.93687602 0.63038926 1.24539173\n","  1.06308877 0.79328506 0.42252854]]\n","C = 1\n","Coefficients:  [[1.19438222 0.9631969  0.94557558 0.96479922 0.66032392 1.27961931\n","  1.10285313 0.80813539 0.38518299]]\n","Kernel: linear\n","C = 0.0001\n","Coefficients:  [[0.06651126 0.06478033 0.05949256 0.06614627 0.05101285 0.07316202\n","  0.06274074 0.05585116 0.06117923]]\n","C = 0.001\n","Coefficients:  [[0.46890885 0.44807214 0.40243314 0.44816947 0.32406622 0.50951894\n","  0.43386823 0.36965919 0.39665788]]\n","C = 0.01\n","Coefficients:  [[0.91450745 0.81739113 0.7384349  0.78967105 0.49912002 1.00538395\n","  0.84357146 0.63349725 0.49461855]]\n","C = 0.1\n","Coefficients:  [[1.14775898 0.93280561 0.91078082 0.93687602 0.63038926 1.24539173\n","  1.06308877 0.79328506 0.42252854]]\n","C = 1\n","Coefficients:  [[1.19438222 0.9631969  0.94557558 0.96479922 0.66032392 1.27961931\n","  1.10285313 0.80813539 0.38518299]]\n","Kernel: poly\n","C = 0.0001\n","Coefficients:  [[0.06651126 0.06478033 0.05949256 0.06614627 0.05101285 0.07316202\n","  0.06274074 0.05585116 0.06117923]]\n","C = 0.001\n","Coefficients:  [[0.46890885 0.44807214 0.40243314 0.44816947 0.32406622 0.50951894\n","  0.43386823 0.36965919 0.39665788]]\n","C = 0.01\n","Coefficients:  [[0.91450745 0.81739113 0.7384349  0.78967105 0.49912002 1.00538395\n","  0.84357146 0.63349725 0.49461855]]\n","C = 0.1\n","Coefficients:  [[1.14775898 0.93280561 0.91078082 0.93687602 0.63038926 1.24539173\n","  1.06308877 0.79328506 0.42252854]]\n","C = 1\n","Coefficients:  [[1.19438222 0.9631969  0.94557558 0.96479922 0.66032392 1.27961931\n","  1.10285313 0.80813539 0.38518299]]\n","Kernel: precomputed\n","C = 0.0001\n","Coefficients:  [[0.06651126 0.06478033 0.05949256 0.06614627 0.05101285 0.07316202\n","  0.06274074 0.05585116 0.06117923]]\n","C = 0.001\n","Coefficients:  [[0.46890885 0.44807214 0.40243314 0.44816947 0.32406622 0.50951894\n","  0.43386823 0.36965919 0.39665788]]\n","C = 0.01\n","Coefficients:  [[0.91450745 0.81739113 0.7384349  0.78967105 0.49912002 1.00538395\n","  0.84357146 0.63349725 0.49461855]]\n","C = 0.1\n","Coefficients:  [[1.14775898 0.93280561 0.91078082 0.93687602 0.63038926 1.24539173\n","  1.06308877 0.79328506 0.42252854]]\n","C = 1\n","Coefficients:  [[1.19438222 0.9631969  0.94557558 0.96479922 0.66032392 1.27961931\n","  1.10285313 0.80813539 0.38518299]]\n","Kernel: rbf\n","C = 0.0001\n","Coefficients:  [[0.06651126 0.06478033 0.05949256 0.06614627 0.05101285 0.07316202\n","  0.06274074 0.05585116 0.06117923]]\n","C = 0.001\n","Coefficients:  [[0.46890885 0.44807214 0.40243314 0.44816947 0.32406622 0.50951894\n","  0.43386823 0.36965919 0.39665788]]\n","C = 0.01\n","Coefficients:  [[0.91450745 0.81739113 0.7384349  0.78967105 0.49912002 1.00538395\n","  0.84357146 0.63349725 0.49461855]]\n","C = 0.1\n","Coefficients:  [[1.14775898 0.93280561 0.91078082 0.93687602 0.63038926 1.24539173\n","  1.06308877 0.79328506 0.42252854]]\n","C = 1\n","Coefficients:  [[1.19438222 0.9631969  0.94557558 0.96479922 0.66032392 1.27961931\n","  1.10285313 0.80813539 0.38518299]]\n"]}],"source":["from sklearn.svm import SVC\n","X_svc = X.iloc[:10000, :]\n","y_svc = y[:10000]\n","\n","for ker in {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}:\n","    print('Kernel: '+ker)\n","    for c in [1e-4, 1e-3, 0.01, 0.1, 1]:\n","        print('C = {}'.format(c))\n","        svc = SVC(C= c, kernel='linear', gamma='auto')\n","        svc.fit(X_svc.values, y_svc.values)\n","        print('Coefficients: ', svc.coef_)"]},{"cell_type":"markdown","metadata":{"id":"sfsLap6cqBuR"},"source":["Обучим модель с оптимальным значением параметра **С** и типом ядра **kernel**. Сохраним точность прогноза в словаре **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scitVGNbqBuS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: svc\n","Mean score = 0.84370\n"]}],"source":["svc = SVC(C=1, kernel='rbf', gamma='auto')\n","score = train(svc, 'svc', class_accuracy, kf, X_svc, y_svc)\n","scores['svc'] = score"]},{"cell_type":"markdown","metadata":{"id":"VNehNP8gqBuS"},"source":["## Дерево решений"]},{"cell_type":"markdown","metadata":{"id":"UP-bW4hwqBuS"},"source":["В модели дерева решений (Decision Tree) в процессе обучения строится алгоритм, по которому выполняется прогноз модели. При этом алгоритм представляет из себя дерево, каждый лист которого - это проверка на то, что какой-либо признак из обучающей выборки принимает определенное значение. Пример дерева решений приведен на рисунке ниже.\n","![Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png)\n","\n","Преимуществами такого метода являются:\n","- простота визуализации и хорошая интерпретируемость алгоритма прогноза\n","- не требуется нормализация данных\n","- скорость прогноза пропорциональна логарифму объема выборки, т.е. этот метод быстрый\n","- может обрабатывать как числовые, так и категориальные данные\n","\n","Недостатками метода являются:\n","- деревья легко переобучаются\n","- небольшие изменения в обучающей выборке могут привести к перестойке всего дерева, т.е. метод нестабилен\n","- предсказания деревьев являются кусочно-постоянными, поэтому не годятся для экстраполирования\n","- требуется сбалансировать обучающую выборку по классам, чтобы не допустить \"перекоса\" дерева в сторону какого-либо класса\n","\n","Конкретную математическую реализалицаю алгоритма построения дерева решений можно изучить, например, [здесь.](https://scikit-learn.org/stable/modules/tree.html)\n","\n","Создадим модель [**DecisionTreeClassifier**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier 'DecisionTreeClassifier') и обучим ее. Для того, чтобы предотвратить переобучение дерева, обычно ограничивается максимальная глубина дерева - параметр **max_depth**, а также минимальное число элементов из обучающей выборки, приходящееся на определнный лист, чтобы можно было с него сделать новое ветвление - параметр **min_samples_split**.\n","\n","Подберите оптимальное значение параметров **max_depth** и **min_samples_split**."]},{"cell_type":"markdown","metadata":{"id":"3dc10J6-qq_P"},"source":["#### **Задание 6** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSShPADxqBuT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Depth: 10\n","Sample: 10\n","Coefficients:  [0.05857012 0.05940114 0.04718149 0.07237071 0.42470187 0.06622509\n"," 0.0388939  0.07714415 0.15551152]\n","Sample: 20\n","Coefficients:  [0.05857243 0.05938926 0.04718335 0.07236207 0.42471862 0.0662277\n"," 0.03889544 0.07713347 0.15551766]\n","Sample: 30\n","Coefficients:  [0.0585759  0.0593817  0.04718614 0.07236635 0.42472216 0.06622042\n"," 0.03889774 0.07712659 0.15552299]\n","Sample: 40\n","Coefficients:  [0.05857692 0.05938274 0.04718696 0.07236761 0.42473025 0.06622158\n"," 0.03889842 0.0771157  0.15551983]\n","Sample: 50\n","Coefficients:  [0.0585777  0.0593894  0.04718759 0.07236858 0.42473004 0.06621697\n"," 0.03889894 0.07711673 0.15551406]\n","Depth: 20\n","Sample: 10\n","Coefficients:  [0.07533253 0.07552562 0.06642192 0.0841135  0.32924147 0.07970921\n"," 0.06025537 0.08838683 0.14101355]\n","Sample: 20\n","Coefficients:  [0.0728492  0.07347405 0.06367978 0.08246318 0.34222878 0.07840164\n"," 0.05712501 0.08702178 0.14275657]\n","Sample: 30\n","Coefficients:  [0.07114914 0.07203652 0.06205465 0.08123628 0.35173841 0.07667764\n"," 0.05496955 0.08591438 0.14422343]\n","Sample: 40\n","Coefficients:  [0.07035287 0.07075688 0.06067471 0.08025689 0.35870991 0.07576796\n"," 0.05311335 0.08510549 0.14526195]\n","Sample: 50\n","Coefficients:  [0.06941223 0.07000543 0.05921408 0.07964104 0.36428322 0.07478194\n"," 0.05188485 0.08464745 0.14612976]\n","Depth: 30\n","Sample: 10\n","Coefficients:  [0.07883001 0.0789088  0.07135084 0.08719539 0.30712205 0.08318854\n"," 0.06516168 0.09057526 0.13766742]\n","Sample: 20\n","Coefficients:  [0.07547344 0.07581746 0.06748481 0.08462272 0.32584362 0.0808261\n"," 0.06079947 0.08849218 0.14064021]\n","Sample: 30\n","Coefficients:  [0.07317773 0.07379879 0.06468046 0.0831424  0.33899087 0.07859062\n"," 0.05798124 0.0872257  0.1424122 ]\n","Sample: 40\n","Coefficients:  [0.07177933 0.07217513 0.06300713 0.0818404  0.34822152 0.07738358\n"," 0.05554688 0.0862174  0.14382862]\n","Sample: 50\n","Coefficients:  [0.07070501 0.07116558 0.06115577 0.08092189 0.35548782 0.07612851\n"," 0.05388301 0.08549971 0.14505271]\n","Depth: 40\n","Sample: 10\n","Coefficients:  [0.07908286 0.07887809 0.0716111  0.08732238 0.30591699 0.08349422\n"," 0.06539473 0.09059954 0.13770009]\n","Sample: 20\n","Coefficients:  [0.07568538 0.07588291 0.06760808 0.08478264 0.32511268 0.08094213\n"," 0.06092258 0.08855273 0.14051086]\n","Sample: 30\n","Coefficients:  [0.07322782 0.07388521 0.06498839 0.0832106  0.338449   0.07863277\n"," 0.05812212 0.0871419  0.14234219]\n","Sample: 40\n","Coefficients:  [0.07200958 0.0722452  0.06311999 0.08186581 0.34774682 0.077343\n"," 0.05572157 0.0861874  0.14376062]\n","Sample: 50\n","Coefficients:  [0.07078496 0.07121786 0.06126933 0.0809631  0.35510191 0.07615007\n"," 0.0540309  0.08553471 0.14494715]\n","Depth: 50\n","Sample: 10\n","Coefficients:  [0.07904599 0.07892755 0.07162112 0.08735066 0.30572731 0.08351189\n"," 0.06560976 0.09048743 0.13771828]\n","Sample: 20\n","Coefficients:  [0.07578466 0.07588375 0.06762874 0.08471612 0.32512461 0.08094176\n"," 0.06098242 0.08856867 0.14036927]\n","Sample: 30\n","Coefficients:  [0.07324871 0.07395834 0.06498876 0.08324663 0.33838873 0.07860733\n"," 0.05802511 0.08730043 0.14223596]\n","Sample: 40\n","Coefficients:  [0.07198905 0.07233245 0.06302671 0.08180484 0.34774484 0.07736902\n"," 0.05568457 0.08625397 0.14379455]\n","Sample: 50\n","Coefficients:  [0.07080384 0.0712327  0.06128999 0.08100447 0.35511476 0.07612505\n"," 0.05401661 0.08551464 0.14489796]\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","for depth in range (10, 60,10):\n","    print('Depth: '+str(depth))\n","    for samples in range(10, 60, 10):\n","        print('Sample: '+str(samples))\n","        dtc = DecisionTreeClassifier(max_depth=depth, min_samples_split=samples, min_samples_leaf=1, random_state=0)\n","        dtc.fit(X.values, y.values)\n","        print('Coefficients: ', dtc.feature_importances_)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NJB7z7RiqBuU"},"source":["Создадим модель с оптимальными значениями параметров **max_depth** и **min_samples_split**. Добавим ее в словарь **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STjh7rAuqBuU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train model: decision tree\n","Mean score = 0.85432\n"]}],"source":["dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=1, random_state=0)\n","score = train(dtc, 'decision tree', class_accuracy, kf, X, y)\n","scores['decision tree'] = score"]},{"cell_type":"markdown","metadata":{"id":"L54zzd7KqBuU"},"source":["## Сравнение различных моделей"]},{"cell_type":"markdown","metadata":{"id":"xEaMPqy-qBuU"},"source":["Отобразим на графике точность работы каждой построенной модели. Для этого будем использовать значения из словаря **scores**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6SRzljXqBuV"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(10,5))\n","xx = list(scores.keys())\n","yy = list(scores.values())\n","rects = plt.bar(xx, yy)\n","plt.ylim(0.6, 0.9)\n","plt.ylabel('Accuracy')\n","for i, rect in enumerate(rects):\n","    yloc = rect.get_height()\n","    xloc = rect.get_x() + rect.get_width() / 4\n","    plt.annotate(round(yy[i], 4), xy=(xloc, yloc), xytext=(xloc, 10),\n","                            textcoords=\"offset points\",\n","                            va='center',\n","                            color='black', clip_on=True)"]},{"cell_type":"markdown","metadata":{"id":"mFqOwK_mqBuV"},"source":["# Выводы"]},{"cell_type":"markdown","metadata":{"id":"u_haAZPuqwqf"},"source":["#### **Задание 7** "]},{"cell_type":"markdown","metadata":{"id":"XXjkE-WUqBuV"},"source":["Напишите выводы по лабораторной работе"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfKKrNttqBuW"},"outputs":[],"source":["#По результатам испытаний шести методов машинного обучения выяснилось, что метод дерева решений дает наивысшую точность, \n","#но при этом является самым затратным по времени. "]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"}}},"nbformat":4,"nbformat_minor":0}
